use rand::Rng; // Nh·ªõ trait n√†y ƒë·ªÉ d√πng random_bool
use rayon::prelude::*;
use std::fs::File; // <--- Th√™m File
use std::io::BufReader; // <--- Th√™m BufReader
use std::sync::{Arc, Mutex, RwLock}; // C·∫ßn Mutex cho PBT
use std::time::Duration;
use std::{env, thread}; // <--- Th√™m thread
use threes_rs::hotload_config::HotLoadConfig;
use threes_rs::{
    n_tuple_network::NTupleNetwork, pbt::PBTManager, pbt::TrainingConfig, python_module::ThreesEnv,
}; // <--- Th√™m Duration

struct SharedBrain {
    network: *mut NTupleNetwork,
}

#[derive(Clone, Copy, Debug, PartialEq)] // Derive Copy ƒë·ªÉ truy·ªÅn v√†o thread kh√¥ng b·ªã move
enum TrainingPolicy {
    Greedy,
    Expectimax,
}

unsafe impl Send for SharedBrain {}
unsafe impl Sync for SharedBrain {}

fn main() {
    let num_threads = 8;

    let gamma = 0.995;

    let args: Vec<String> = env::args().collect();

    // N·∫øu ch·∫°y: cargo run -- 2000000
    // Th√¨ n√≥ s·∫Ω t·ª± hi·ªÉu l√† resume t·ª´ 2 tri·ªáu
    let resume_from_episode = if args.len() > 1 {
        args[1].parse::<usize>().unwrap_or(0) as u32
    } else {
        0 as u32
    };

    // 2. Tham s·ªë Policy (Index 2) - M·ªöI
    let policy_arg = if args.len() > 2 {
        args[2].to_lowercase()
    } else {
        "greedy".to_string() // M·∫∑c ƒë·ªãnh l√† Greedy n·∫øu kh√¥ng nh·∫≠p
    };

    let training_policy = match policy_arg.as_str() {
        "expect" | "expectimax" => {
            println!("üß† Training Mode: EXPECTIMAX (Ch·∫≠m nh∆∞ng ch·∫Øc)");
            TrainingPolicy::Expectimax
        }
        _ => {
            println!("‚ö° Training Mode: GREEDY (T·ªëc ƒë·ªô b√†n th·ªù)");
            TrainingPolicy::Greedy
        }
    };

    let chunk_episodes = 1_000_000;
    let current_target = resume_from_episode + chunk_episodes;

    println!(
        "üöÄ B·∫Øt ƒë·∫ßu t·ª´: {} | M·ª•c ti√™u ƒë·ª£t n√†y: {}",
        resume_from_episode, current_target
    );

    // T·ªïng ƒë√≠ch ƒë·∫øn (ƒë·ªÉ t√≠nh Alpha decay cho chu·∫©n)
    // V√≠ d·ª• m·ª•c ti√™u cu·ªëi c√πng l√† 10 tri·ªáu
    let total_target_episodes = 100_000_000;

    // --- S·ª¨A L·ªñI LOADING ·ªû ƒê√ÇY ---
    let mut brain = if resume_from_episode > 0 {
        let filename = format!("brain_ep_{}.msgpack", resume_from_episode);
        println!("üìÇ ƒêang load n√£o t·ª´ checkpoint: {}", filename);

        let b = NTupleNetwork::load_from_msgpack(&filename).expect("Kh√¥ng t√¨m th·∫•y file!");

        // [DEBUG] In ra ƒë·ªÉ xem n√≥ l√† 0.0 hay l√† s·ªë th·ª±c
        println!(
            "üßê CHECK DATA G·ªêC: Empty={:.4}, Snake={:.4}",
            b.w_empty, b.w_snake
        );
        b
    } else {
        println!("‚ú® T·∫°o n√£o m·ªõi tinh...");
        NTupleNetwork::new(0.1, 0.995)
    };
    // -----------------------------

    let brain_ptr = SharedBrain {
        network: &mut brain as *mut NTupleNetwork,
    };
    let shared_brain = Arc::new(brain_ptr);

    // 1. T·∫°o bi·∫øn HotConfig chia s·∫ª
    let hot_config = Arc::new(RwLock::new(HotLoadConfig::default()));

    // 2. B·∫≠t Watcher
    start_config_watcher(hot_config.clone());
    println!("üëÄ ƒê√£ b·∫≠t Hot Reload. H√£y s·ª≠a file config.json ƒë·ªÉ can thi·ªáp!");

    // 2. KH·ªûI T·∫†O PBT MANAGER (D√πng Mutex ƒë·ªÉ c√°c lu·ªìng tranh nhau b√°o c√°o)
    // PBTManager::new() l√† h√†m b√°c ƒë√£ vi·∫øt ·ªü b∆∞·ªõc tr∆∞·ªõc
    let pbt_manager = Arc::new(Mutex::new(PBTManager::new()));

    println!("üöÄ B·∫Øt ƒë·∫ßu luy·ªán ƒëan PBT v·ªõi {} lu·ªìng...", num_threads);

    (0..num_threads).into_par_iter().for_each(|t_id| {
        let mut local_env = ThreesEnv::new(gamma);
        let ep_per_thread = chunk_episodes as u32 / num_threads;

        run_training_parallel(
            &mut local_env,
            shared_brain.clone(),
            pbt_manager.clone(),
            hot_config.clone(),
            ep_per_thread,         // S·ªë v√°n c·∫ßn ch·∫°y ƒë·ª£t n√†y
            total_target_episodes, // T·ªïng ƒë√≠ch (ƒë·ªÉ t√≠nh t·ª∑ l·ªá %)
            resume_from_episode,   // <--- TRUY·ªÄN TH√äM OFFSET V√ÄO
            t_id,
            num_threads,
            training_policy,
        );
    });

    // Save cu·ªëi c√πng c≈©ng d√πng msgpack
    let end_episode = resume_from_episode + chunk_episodes;
    let filename = format!("brain_ep_{}.msgpack", end_episode);
    brain.export_to_msgpack(&filename).expect("L·ªói l∆∞u file");
}

// --- H√ÄM WATCHER: Ch·∫°y ng·∫ßm ƒë·ªÉ ƒë·ªçc file json ---
fn start_config_watcher(shared_hot_config: Arc<RwLock<HotLoadConfig>>) {
    thread::spawn(move || {
        loop {
            thread::sleep(Duration::from_secs(2)); // Check m·ªói 2 gi√¢y

            if let Ok(file) = File::open("config.json") {
                let reader = BufReader::new(file);
                // Parse JSON v√†o struct
                if let Ok(new_cfg) = serde_json::from_reader(reader) {
                    let mut write_guard = shared_hot_config.write().unwrap();
                    *write_guard = new_cfg;
                }
            }
        }
    });
}

fn run_training_parallel(
    env: &mut ThreesEnv,
    shared_brain: Arc<SharedBrain>,
    pbt: Arc<Mutex<PBTManager>>,
    hot_config: Arc<RwLock<HotLoadConfig>>,
    episodes_to_run: u32,
    total_target_episodes: u32,
    start_offset: u32,
    thread_id: u32,
    num_threads: u32,
    policy: TrainingPolicy,
) {
    let mut rng = rand::rng();
    let mut running_error = 0.0;
    let mut running_score = 0.0;

    // 1. L·∫§Y BRAIN TR∆Ø·ªöC (ƒê·ªÉ c√≥ d·ªØ li·ªáu resume)
    let ptr = shared_brain.network;
    let brain = unsafe { &mut *ptr };

    // 2. KH·ªûI T·∫†O PBT_CONFIG (X·ª≠ l√Ω c·∫£ Resume v√† Train l·∫ßn ƒë·∫ßu)
    let mut pbt_config = if thread_id == 0 {
        TrainingConfig {
            // N·∫øu n√£o c√≥ gi√° tr·ªã (>0) th√¨ l·∫•y gi√° tr·ªã ƒë√≥ (Resume)
            // N·∫øu kh√¥ng (l·∫ßn ƒë·∫ßu) th√¨ l·∫•y s·ªë m·∫∑c ƒë·ªãnh an to√†n (v√≠ d·ª• 40.0 v√† 50.0)
            w_empty: if brain.w_empty > 0.0 {
                brain.w_empty
            } else {
                50.0
            },
            w_snake: if brain.w_snake > 0.0 {
                brain.w_snake
            } else {
                50.0
            },
        }
    } else {
        // C√°c thread kh√°c: N·∫øu n√£o r·ªóng th√¨ random r·ªông, n·∫øu c√≥ n√£o th√¨ bi·∫øn ƒë·ªông quanh n√£o
        let (base_empty, base_snake) = if brain.w_empty > 0.0 {
            (brain.w_empty, brain.w_snake)
        } else {
            (rng.random_range(30.0..60.0), rng.random_range(20.0..80.0))
        };

        TrainingConfig {
            w_empty: (base_empty * rng.random_range(0.8..1.2)).clamp(1.0, 500.0),
            w_snake: (base_snake * rng.random_range(0.8..1.2)).clamp(0.0, 1000.0),
        }
    };

    // --- V√íNG L·∫∂P CH√çNH ---
    for local_ep in 0..episodes_to_run {
        let current_global_ep = (local_ep * num_threads + thread_id) + start_offset;
        let progress = current_global_ep as f32 / total_target_episodes as f32;

        // 3. X·ª¨ L√ù HOT CONFIG & MERGE
        let current_hot = *hot_config.read().unwrap();
        let mut effective_config = pbt_config;

        if current_hot.w_empty_override > 0.0 {
            effective_config.w_empty = current_hot.w_empty_override;
        }
        if current_hot.w_snake_override > 0.0 {
            effective_config.w_snake = current_hot.w_snake_override;
        }

        // √Åp d·ª•ng config v√†o m√¥i tr∆∞·ªùng ch∆°i game
        env.set_config(effective_config);

        // 4. ALPHA & EPSILON DECAY
        let mut current_alpha = (0.1 * (1.0 - progress)).max(0.001);
        if current_hot.alpha_override > 0.0 {
            current_alpha = current_hot.alpha_override;
        }
        let current_epsilon = (0.5 * (1.0 - (progress / 0.8))).max(0.01);

        // 5. TRAINING STEP
        env.reset();
        while !env.game.game_over {
            // Logic ch·ªçn n∆∞·ªõc ƒëi (Action Selection)
            let action = if rng.random_bool(current_epsilon.into()) {
                // Epsilon-Greedy: V·∫´n gi·ªØ t·ª∑ l·ªá ng·∫´u nhi√™n ƒë·ªÉ kh√°m ph√°
                env.get_random_valid_action()
            } else {
                // Khai th√°c (Exploitation) d·ª±a tr√™n Policy ƒë√£ ch·ªçn
                match policy {
                    TrainingPolicy::Greedy => env.get_best_action_greedy(brain),
                    TrainingPolicy::Expectimax => {
                        // B√°c c·∫ßn ƒë·∫£m b·∫£o h√†m n√†y ƒë√£ c√≥ trong ThreesEnv nh√©!
                        env.get_best_action_expectimax(brain)
                    }
                }
            };

            let (error, _) = env.train_step(brain, action, current_alpha);
            running_error = running_error * 0.9999 + error * 0.0001;
        }
        running_score = running_score * 0.99 + env.game.score as f32 * 0.01;

        // 6. PBT EVOLVE
        if local_ep > 0 && local_ep % 1000 == 0 {
            let mut pbt_guard = pbt.lock().unwrap();
            let (evolved, new_cfg) =
                pbt_guard.report_and_evolve(thread_id, running_score, pbt_config);
            if evolved {
                pbt_config = new_cfg;
            }
        }

        // 7. LOGGING & SAVING (Thread 0 ƒë·∫£m nhi·ªám)
        if thread_id == 0 {
            // Log m·ªói 500 v√°n c·ªßa Thread 0 (ƒë·ªÉ theo d√µi ti·∫øn ƒë·ªô)
            if local_ep % 500 == 0 {
                println!(
                    "Ep: {:>8} | Err: {:.4} | Sc: {:>5.0} | Emp: {:.1} | Snk: {:.1} | Alp: {:.5}",
                    current_global_ep,
                    running_error,
                    running_score,
                    effective_config.w_empty,
                    effective_config.w_snake,
                    current_alpha
                );
            }

            // ƒêI·ªÄU KI·ªÜN SAVE: Ch·ªâ save khi ch·∫°y xong v√°n cu·ªëi c√πng c·ªßa ƒë·ª£t n√†y
            // local_ep ch·∫°y t·ª´ 0 ƒë·∫øn (episodes_to_run - 1)
            if local_ep == episodes_to_run - 1 {
                // T√≠nh to√°n con s·ªë t·ªïng k·∫øt ch√≠nh x√°c
                let end_ep_of_chunk = start_offset + (episodes_to_run * num_threads);

                let filename = format!("brain_ep_{}.msgpack", end_ep_of_chunk);

                // C·∫≠p nh·∫≠t config m·ªõi nh·∫•t v√†o n√£o ƒë·ªÉ mang ƒëi save
                brain.w_empty = pbt_config.w_empty;
                brain.w_snake = pbt_config.w_snake;

                if let Err(e) = brain.export_to_msgpack(&filename) {
                    eprintln!("‚ùå L·ªói l∆∞u file: {}", e);
                } else {
                    println!(
                        "üíæ [DONE] ƒê√£ ho√†n th√†nh Chunk. File checkpoint: {}",
                        filename
                    );
                }
            }
        }
    }
}
