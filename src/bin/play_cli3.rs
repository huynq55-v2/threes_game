use rand::Rng;
use rayon::prelude::*;
use std::fs::File;
use std::io::BufReader;
use std::sync::{Arc, Mutex, RwLock};
use std::time::Duration;
use std::{env, thread};
use threes_rs::hotload_config::HotLoadConfig;
use threes_rs::{
    n_tuple_network::NTupleNetwork, pbt::PBTManager, pbt::TrainingConfig, python_module::ThreesEnv,
};

// H·∫±ng s·ªë T·ª∑ l·ªá v√†ng
const GOLDEN_RATIO: f64 = 1.61803398875;

// Struct wrapper pointer (gi·ªØ nguy√™n)
struct SharedBrain {
    network: *mut NTupleNetwork,
}

#[derive(Clone, Copy, Debug, PartialEq)]
enum TrainingPolicy {
    Greedy,
    Expectimax,
}

unsafe impl Send for SharedBrain {}
unsafe impl Sync for SharedBrain {}

fn main() {
    let num_threads = 8;
    let gamma = 0.995;
    let args: Vec<String> = env::args().collect();

    // Episode override (n·∫øu mu·ªën force t·ª´ d√≤ng l·ªánh, kh√¥ng th√¨ l·∫•y t·ª´ file)
    let override_episode = if args.len() > 1 {
        args[1].parse::<usize>().unwrap_or(0) as u32
    } else {
        0 as u32
    };

    // Policy
    let policy_arg = if args.len() > 2 {
        args[2].to_lowercase()
    } else {
        "expect".to_string()
    };

    let training_policy = match policy_arg.as_str() {
        "greedy" => {
            println!("‚ö° Training Mode: GREEDY");
            TrainingPolicy::Greedy
        }
        _ => {
            println!("üß† Training Mode: EXPECTIMAX");
            TrainingPolicy::Expectimax
        }
    };

    let multiplier = args[3].to_lowercase();

    let mut BUFF_MULTIPLIER = 1.0;

    if multiplier == "mul" {
        BUFF_MULTIPLIER = GOLDEN_RATIO;
    } else if multiplier == "div" {
        BUFF_MULTIPLIER = 1.0 / GOLDEN_RATIO;
    }

    println!("Multiplier: {}", multiplier);

    // --- SETUP BRAIN ---
    let mut brain = if override_episode > 0 {
        let filename = format!("brain_ep_{}.msgpack", override_episode);
        println!("üìÇ Loading brain: {}", filename);
        let b = NTupleNetwork::load_from_msgpack(&filename).expect("Kh√¥ng t√¨m th·∫•y file!");
        println!(
            "üßê LOAD DATA: E={:.1}, S={:.1}, M={:.1}, D={:.1}",
            b.w_empty, b.w_snake, b.w_merge, b.w_disorder
        );
        b
    } else {
        println!("‚ú® T·∫°o n√£o m·ªõi tinh...");
        NTupleNetwork::new(0.1, gamma)
    };

    if override_episode > 0 && brain.total_episodes == 0 {
        brain.total_episodes = override_episode;
    }

    let mut current_global_episode = brain.total_episodes;

    // Safety checks
    if brain.w_empty == 0.0 {
        brain.w_empty = 50.0;
    }
    if brain.w_snake == 0.0 {
        brain.w_snake = 50.0;
    }
    if brain.w_merge == 0.0 {
        brain.w_merge = 50.0;
    }
    if brain.w_disorder == 0.0 {
        brain.w_disorder = 50.0;
    }

    // Pointer setup
    let brain_ptr = SharedBrain {
        network: &mut brain as *mut NTupleNetwork,
    };
    let shared_brain = Arc::new(brain_ptr);

    // Config Watcher & PBT
    let hot_config = Arc::new(RwLock::new(HotLoadConfig::default()));
    start_config_watcher(hot_config.clone());
    let pbt_manager = Arc::new(Mutex::new(PBTManager::new()));

    let chunk_episodes = 100_000;
    let total_target_episodes = 100_000_000;

    // --- LOGIC M·ªöI: THEO D√ïI BEST TOP 1% ---
    // Kh·ªüi t·∫°o m·ª©c ƒëi·ªÉm chu·∫©n ban ƒë·∫ßu (c√≥ th·ªÉ set 0 ho·∫∑c ch·∫°y th·ª≠ 1 v√≤ng test ƒë·ªÉ l·∫•y)
    let mut best_top1_percent_avg = 0.0;

    // Backup n√£o t·ªët nh·∫•t hi·ªán t·∫°i (Deep Clone)
    // L∆∞u √Ω: NTupleNetwork ph·∫£i h·ªó tr·ª£ Clone. N·∫øu ch∆∞a c√≥, b·∫°n c·∫ßn th√™m #[derive(Clone)] v√†o struct NTupleNetwork
    let mut best_stable_brain = brain.clone();

    println!("üöÄ B·∫Øt ƒë·∫ßu Training v·ªõi Logic: Top 1% Average & Auto-Revert...");

    loop {
        let start_time = std::time::Instant::now();

        // B∆∞·ªõc 0: LU√îN RESET V·ªÄ TR·∫†NG TH√ÅI ·ªîN ƒê·ªäNH NH·∫§T
        // N·∫øu v√≤ng tr∆∞·ªõc fail, brain s·∫Ω quay v·ªÅ nh∆∞ ch∆∞a t·ª´ng train v√≤ng ƒë√≥.
        // N·∫øu v√≤ng tr∆∞·ªõc win, best_stable_brain ƒë√£ ƒë∆∞·ª£c update ·ªü cu·ªëi v√≤ng l·∫∑p.
        brain = best_stable_brain.clone();

        // C·∫≠p nh·∫≠t l·∫°i pointer tr·ªè v√†o brain m·ªõi reset
        // (L∆∞u √Ω: SharedBrain d√πng pointer raw, n√™n ta g√°n ƒë√® d·ªØ li·ªáu v√†o v√πng nh·ªõ c≈©
        // ho·∫∑c t·∫°o Arc m·ªõi. ·ªû ƒë√¢y v√¨ c·∫•u tr√∫c main, ta c·∫ßn ƒë·∫£m b·∫£o pointer tr·ªè ƒë√∫ng)
        // C√°ch an to√†n nh·∫•t trong loop n√†y l√† t·∫°o SharedBrain m·ªõi cho m·ªói v√≤ng l·∫∑p
        // v√¨ bi·∫øn `brain` b·ªã move/clone l·∫°i.
        let brain_ptr = SharedBrain {
            network: &mut brain as *mut NTupleNetwork,
        };
        let shared_brain_loop = Arc::new(brain_ptr);

        // ------------------------------------------------------
        // 1. LOGIC BUFF (Random 1 ch·ªâ s·ªë)
        // ------------------------------------------------------
        let mut rng = rand::rng();
        let buff_idx = rng.random_range(0..4);
        let old_vals = (
            brain.w_empty,
            brain.w_snake,
            brain.w_merge,
            brain.w_disorder,
        );

        match buff_idx {
            0 => {
                brain.w_empty *= BUFF_MULTIPLIER;
                print!("‚ú® BUFF EMPTY! ");
            }
            1 => {
                brain.w_snake *= BUFF_MULTIPLIER;
                print!("üêç BUFF SNAKE! ");
            }
            2 => {
                brain.w_merge *= BUFF_MULTIPLIER;
                print!("üîó BUFF MERGE! ");
            }
            _ => {
                brain.w_disorder *= BUFF_MULTIPLIER;
                print!("‚ö° BUFF DISORDER! ");
            }
        }

        println!(
            "-> Test Config: {:.1}/{:.1}/{:.1}/{:.1}",
            brain.w_empty, brain.w_snake, brain.w_merge, brain.w_disorder
        );

        // ------------------------------------------------------
        // 2. CH·∫†Y SONG SONG & THU TH·∫¨P ƒêI·ªÇM S·ªê
        // ------------------------------------------------------
        let ep_per_thread = chunk_episodes as u32 / num_threads;

        let current_ep_for_decay = brain.total_episodes;

        // S·ª≠ d·ª•ng map c·ªßa rayon ƒë·ªÉ thu v·ªÅ vector ƒëi·ªÉm s·ªë t·ª´ c√°c lu·ªìng
        let results: Vec<Vec<f64>> = (0..num_threads)
            .into_par_iter()
            .map(|t_id| {
                let mut local_env = ThreesEnv::new(gamma);

                // H√†m run gi·ªù s·∫Ω tr·∫£ v·ªÅ danh s√°ch ƒëi·ªÉm s·ªë c·ªßa n√≥
                run_training_parallel(
                    &mut local_env,
                    shared_brain_loop.clone(),
                    pbt_manager.clone(),
                    hot_config.clone(),
                    ep_per_thread,
                    total_target_episodes,
                    current_ep_for_decay,
                    t_id,
                    num_threads,
                    training_policy,
                    BUFF_MULTIPLIER,
                )
            })
            .collect();

        // G·ªôp t·∫•t c·∫£ ƒëi·ªÉm s·ªë l·∫°i th√†nh 1 list l·ªõn
        let mut all_scores: Vec<f64> = results.into_iter().flatten().collect();

        // ------------------------------------------------------
        // 3. T√çNH TO√ÅN METRIC (TOP 1% AVG)
        // ------------------------------------------------------
        // S·∫Øp x·∫øp gi·∫£m d·∫ßn ƒë·ªÉ l·∫•y ƒëi·ªÉm cao nh·∫•t
        all_scores.sort_by(|a, b| b.partial_cmp(a).unwrap());

        let top_1_percent_count = (all_scores.len() as f64 * 0.01).ceil() as usize;
        let top_1_percent_count = top_1_percent_count.max(1); // √çt nh·∫•t 1
        let top_scores = &all_scores[0..top_1_percent_count];

        let sum_top: f64 = top_scores.iter().sum();
        let current_top1_avg = sum_top / top_1_percent_count as f64;

        let duration = start_time.elapsed();
        println!("\nüìä Stats Loop:");
        println!("   - Max Score: {:.0}", all_scores[0]);
        println!("   - Top 1% Avg (Current): {:.2}", current_top1_avg);
        println!(
            "   - Top 1% Avg (Record):  {:.2}",
            best_stable_brain.best_top1_avg
        );

        // ------------------------------------------------------
        // 4. QUY·∫æT ƒê·ªäNH: GI·ªÆ HAY RESET?
        // ------------------------------------------------------
        current_global_episode += chunk_episodes;

        // üîÑ S·ª¨A ƒêI·ªÄU KI·ªÜN: So s√°nh v·ªõi best_stable_brain
        if current_top1_avg > best_stable_brain.best_top1_avg {
            // >>> WIN CASE <<<
            println!("‚úÖ NEW RECORD! Config n√†y ngon. Gi·ªØ l·∫°i network & config.");

            // 1. C·∫≠p nh·∫≠t Stats v√†o Brain
            brain.total_episodes += chunk_episodes;
            brain.best_top1_avg = current_top1_avg;

            // 2. C·∫≠p nh·∫≠t bi·∫øn c·ª•c b·ªô
            current_global_episode = brain.total_episodes;

            // ‚ùå X√ìA D√íNG N√ÄY (Kh√¥ng c·∫ßn bi·∫øn c·ª•c b·ªô n·ªØa):
            // best_top1_percent_avg = current_top1_avg;

            // 3. C·∫≠p nh·∫≠t PBT Config t·ªët nh·∫•t v√†o Brain (Gi·ªØ nguy√™n)
            {
                let pbt = pbt_manager.lock().unwrap();
                if let Some(best_thread) = pbt.get_best_config_entry() {
                    let best_cfg = best_thread.1;
                    brain.w_empty = best_cfg.w_empty;
                    brain.w_snake = best_cfg.w_snake;
                    brain.w_merge = best_cfg.w_merge;
                    brain.w_disorder = best_cfg.w_disorder;
                }
            }

            // 4. L∆ØU "CHECKPOINT C·ª®NG" M·ªöI (Gi·ªØ nguy√™n)
            // L·ªánh n√†y s·∫Ω t·ª± ƒë·ªông l∆∞u `brain.best_top1_avg` m·ªõi v√†o `best_stable_brain`
            // ƒë·ªÉ v√≤ng l·∫∑p sau d√πng l√†m m·ªëc so s√°nh.
            best_stable_brain = brain.clone();

            // 5. L∆∞u File (Gi·ªØ nguy√™n)
            let filename = format!("brain_ep_{}.msgpack", current_global_episode);
            if let Err(e) = brain.export_to_msgpack(&filename) {
                eprintln!("‚ùå L·ªói l∆∞u file: {}", e);
            } else {
                println!("üíæ Saved checkpoint: {}", filename);
            }
        } else {
            // >>> LOSE CASE <<<
            println!("‚ùå FAILED. H·ªßy b·ªè Iteration n√†y.");

            // üîÑ S·ª¨A D√íNG N√ÄY: L·∫•y t·ª´ best_stable_brain
            println!(
                "üîÑ Reverting v·ªÅ tr·∫°ng th√°i c≈© (Ep: {}, Best: {:.2})",
                best_stable_brain.total_episodes, best_stable_brain.best_top1_avg
            );

            // Revert bi·∫øn ƒë·∫øm hi·ªÉn th·ªã b√™n ngo√†i cho ƒë√∫ng th·ª±c t·∫ø
            current_global_episode = best_stable_brain.total_episodes;
        }

        println!("‚è±Ô∏è Time: {:.1}s | Total Ep: {}\n-----------------------------------------------------------", duration.as_secs_f64(), current_global_episode);
    }
}

// H√†m Watcher (Gi·ªØ nguy√™n)
fn start_config_watcher(shared_hot_config: Arc<RwLock<HotLoadConfig>>) {
    thread::spawn(move || loop {
        thread::sleep(Duration::from_secs(2));
        if let Ok(file) = File::open("config.json") {
            let reader = BufReader::new(file);
            if let Ok(new_cfg) = serde_json::from_reader(reader) {
                let mut write_guard = shared_hot_config.write().unwrap();
                *write_guard = new_cfg;
            }
        }
    });
}

// S·ª≠a h√†m run_training_parallel ƒë·ªÉ tr·∫£ v·ªÅ Vec<f64>
fn run_training_parallel(
    env: &mut ThreesEnv,
    shared_brain: Arc<SharedBrain>,
    pbt: Arc<Mutex<PBTManager>>,
    hot_config: Arc<RwLock<HotLoadConfig>>,
    episodes_to_run: u32,
    total_target_episodes: u32,
    start_offset: u32,
    thread_id: u32,
    num_threads: u32,
    policy: TrainingPolicy,
    buff_multiplier: f64,
) -> Vec<f64> {
    // <--- Thay ƒë·ªïi ki·ªÉu tr·∫£ v·ªÅ
    let mut rng = rand::rng();
    let mut running_error = 0.0;
    let mut running_score = 0.0;

    // Vector l∆∞u ƒëi·ªÉm s·ªë c·ªßa thread n√†y
    let mut local_scores = Vec::with_capacity(episodes_to_run as usize);

    // L·∫§Y N√ÉO (UNSAFE)
    let ptr = shared_brain.network;
    let brain = unsafe { &mut *ptr };

    // KH·ªûI T·∫†O CONFIG CHO THREAD N√ÄY
    let mut pbt_config = if thread_id == 0 {
        TrainingConfig {
            w_empty: brain.w_empty,
            w_snake: brain.w_snake,
            w_merge: brain.w_merge,
            w_disorder: brain.w_disorder,
        }
    } else {
        TrainingConfig {
            w_empty: (brain.w_empty * rng.random_range(0.9..1.1)),
            w_snake: (brain.w_snake * rng.random_range(0.9..1.1)),
            w_merge: (brain.w_merge * rng.random_range(0.9..1.1)),
            w_disorder: (brain.w_disorder * rng.random_range(0.9..1.1)),
        }
    };

    for local_ep in 0..episodes_to_run {
        let current_global_ep = (local_ep * num_threads + thread_id) + start_offset;
        let progress = current_global_ep as f64 / total_target_episodes as f64;

        // HOT RELOAD
        let current_hot = *hot_config.read().unwrap();
        let mut effective_config = pbt_config;
        if current_hot.w_empty_override > 0.0 {
            effective_config.w_empty = current_hot.w_empty_override;
        }
        if current_hot.w_snake_override > 0.0 {
            effective_config.w_snake = current_hot.w_snake_override;
        }
        if current_hot.w_merge_override > 0.0 {
            effective_config.w_merge = current_hot.w_merge_override;
        }
        if current_hot.w_disorder_override > 0.0 {
            effective_config.w_disorder = current_hot.w_disorder_override;
        }

        env.set_config(effective_config);

        // Alpha & Epsilon
        let mut current_alpha = (0.01 * (1.0 - progress)).max(0.0001);
        if current_hot.alpha_override > 0.0 {
            current_alpha = current_hot.alpha_override;
        }
        let current_epsilon = (0.2 * (1.0 - (progress / 0.8))).max(0.01);

        // GAME LOOP
        env.reset();
        let mut step_count = 0;
        while !env.game.game_over {
            step_count += 1;
            if step_count > 20000 {
                break;
            }

            let action = if rng.random_bool(current_epsilon.into()) {
                env.get_random_valid_action()
            } else {
                match policy {
                    TrainingPolicy::Greedy => env.get_best_action_greedy(brain),
                    TrainingPolicy::Expectimax => env.get_best_action_expectimax(brain),
                }
            };

            let (error, _) = env.train_step(brain, action, current_alpha);
            running_error = running_error * 0.999 + error * 0.001;
        }

        let final_score = env.game.score as f64;
        running_score = running_score * 0.99 + final_score * 0.01;

        // Push ƒëi·ªÉm v√†o list
        local_scores.push(final_score);

        // PBT EVOLVE
        if local_ep > 0 && local_ep % 1000 == 0 {
            let mut pbt_guard = pbt.lock().unwrap();
            let (evolved, new_cfg) =
                pbt_guard.report_and_evolve(thread_id, running_score, pbt_config, buff_multiplier);
            if evolved {
                pbt_config = new_cfg;
            }
        }

        if thread_id == 0 && local_ep % 1000 == 0 {
            print!(
                "\r   Run: {:>6} | Sc(EMA): {:>5.0} | Cfg: S{:.0} M{:.0}   ",
                local_ep, running_score, effective_config.w_snake, effective_config.w_merge
            );
            use std::io::Write;
            std::io::stdout().flush().unwrap();
        }
    }
    if thread_id == 0 {
        println!();
    }

    // Tr·∫£ v·ªÅ danh s√°ch ƒëi·ªÉm
    local_scores
}
