import gymnasium as gym
import numpy as np
from gymnasium import spaces
from sb3_contrib.common.wrappers import ActionMasker
import threes_rs  # Import thÆ° viá»‡n Rust cá»§a báº¡n
from stable_baselines3.common.monitor import Monitor # <--- Import cÃ¡i nÃ y

class ThreesGymEnv(gym.Env):
    """
    Custom Environment tuÃ¢n thá»§ chuáº©n Gymnasium cho game Threes!
    """
    metadata = {"render_modes": ["human"]}

    def __init__(self):
        super().__init__()
        # Khá»Ÿi táº¡o game tá»« Rust (Giáº£ sá»­ báº¡n cÃ³ class ThreesEnv Ä‘Æ¡n láº» trong Rust binding)
        # Náº¿u Rust chá»‰ cÃ³ VecEnv, báº¡n cáº§n sá»­a Rust Ä‘á»ƒ expose struct Game Ä‘Æ¡n láº», 
        # hoáº·c dÃ¹ng trick gá»i VecEnv vá»›i num_envs=1.
        self.game = threes_rs.ThreesEnv() 
        
        # 1. Action Space: 4 hÆ°á»›ng (0: Up, 1: Down, 2: Left, 3: Right)
        self.action_space = spaces.Discrete(4)
        
        # 2. Observation Space: DÃ¹ng Dict Ä‘á»ƒ chá»©a cáº£ Board vÃ  Hint
        self.observation_space = spaces.Dict({
            # Board: 1 kÃªnh, 4x4, giÃ¡ trá»‹ tá»« 0-15 (Rank)
            "board": spaces.Box(low=0, high=15, shape=(1, 4, 4), dtype=np.float32),
            # Hint: Vector One-hot 13 pháº§n tá»­
            "hint": spaces.Box(low=0, high=1, shape=(13,), dtype=np.float32),
        })
        
        # Mapping giÃ¡ trá»‹ tile sang index (1->0, 2->1, 3->2, ...)
        self.TILE_MAP = {v: i for i, v in enumerate([1, 2, 3, 6, 12, 24, 48, 96, 192, 384, 768, 1536, 3072])}

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        
        # Gá»i Rust reset
        # YÃŠU Cáº¦U: Rust binding pháº£i tráº£ vá» (board_state, hint_value)
        raw_board, raw_hint_set = self.game.reset()
        
        observation = self._process_obs(raw_board, raw_hint_set)
        info = {}
        return observation, info

    def step(self, action):
        # Gá»i Rust step
        # YÃŠU Cáº¦U: Rust binding pháº£i tráº£ vá» (next_board, reward, done, next_hint)
        # Náº¿u Rust tráº£ vá» done dáº¡ng boolean, ta gÃ¡n truncated = False
        next_board, reward, done, next_hint_set = self.game.step(int(action))
        
        # Xá»­ lÃ½ Reward (Scale nhá» láº¡i Ä‘á»ƒ PPO há»c á»•n Ä‘á»‹nh hÆ¡n)
        reward = reward * 0.1

        # --- THÃŠM ÄOáº N NÃ€Y Äá»‚ IN LOG RA MÃ€N HÃŒNH ---
        if done:
            # Láº¥y Max Tile tá»« bÃ n cá»
            # LÆ°u Ã½: next_board Ä‘ang lÃ  list pháº³ng hoáº·c array
            max_val = max(next_board) 
            print(f"ðŸ’€ Game Over! Reward: {reward:.2f} | MaxTile: {max_val}")
        # -------------------------------------------
        
        observation = self._process_obs(next_board, next_hint_set)
        truncated = False 
        info = {}
        
        return observation, reward, done, truncated, info

    def valid_action_mask(self):
        """
        HÃ m quan trá»ng nháº¥t cho Maskable PPO.
        Tráº£ vá» máº£ng boolean [True, False, True, True] tÆ°Æ¡ng á»©ng vá»›i cÃ¡c action Ä‘Æ°á»£c phÃ©p.
        """
        # YÃŠU Cáº¦U: Rust binding cáº§n cÃ³ hÃ m get_valid_moves() tráº£ vá» list bool hoáº·c list int
        valid_moves = self.game.valid_moves() 
        
        # Náº¿u Rust tráº£ vá» [0, 1, 0, 1] (int), ta convert sang bool
        return np.array(valid_moves, dtype=bool)

    def _process_obs(self, flat_board, hint_set):
        """Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ´ tá»« Rust sang Tensor cho Neural Net"""
        
        # 1. Xá»­ lÃ½ Board (Log2 Transform nhÆ° cÅ©)
        board_np = np.array(flat_board, dtype=np.float32)
        ranks = np.zeros_like(board_np)
        ranks[board_np == 1] = 1
        ranks[board_np == 2] = 2
        mask = (board_np >= 3)
        ranks[mask] = np.floor(np.log2(board_np[mask] / 3.0) + 1e-5) + 3
        ranks = np.clip(ranks, 0, 15)
        
        # Reshape vá» (Channel, H, W) -> (1, 4, 4)
        board_final = ranks.reshape(1, 4, 4)
        
        # 2. Xá»­ lÃ½ Hint (One-hot)
        hint_vec = np.zeros((13,), dtype=np.float32)
        # Giáº£ sá»­ hint_set lÃ  list cÃ¡c giÃ¡ trá»‹ [1, 6]
        for h in hint_set:
            if h in self.TILE_MAP:
                hint_vec[self.TILE_MAP[h]] = 1.0
                
        return {
            "board": board_final,
            "hint": hint_vec
        }

# HÃ m helper Ä‘á»ƒ táº¡o env (báº¯t buá»™c cho SubprocVecEnv)
def make_env():
    env = ThreesGymEnv()
    # 1. Action Masker (Ä‘á»ƒ cháº·n nÆ°á»›c Ä‘i sai)
    env = ActionMasker(env, lambda env: env.valid_action_mask())
    
    # 2. Monitor (Ä‘á»ƒ Log Reward vÃ  Moves cho SB3)
    # allow_early_resets=True giÃºp trÃ¡nh lá»—i náº¿u reset game giá»¯a chá»«ng
    env = Monitor(env, allow_early_resets=True) 
    
    return env